{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cab8817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717633a2",
   "metadata": {},
   "source": [
    "# Importing Pupillometry data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a0f81c",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d1798d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_paths = {}\n",
    "\n",
    "midi_paths['P1T1'] = '../MIDI/MIDI-P01-task1.txt'\n",
    "midi_paths['P1T2'] = '../MIDI/MIDI-P01-task2.txt'\n",
    "midi_paths['P1T3'] = '../MIDI/MIDI-P01-task3.txt'\n",
    "midi_paths['P1T4'] = '../MIDI/MIDI-P01-task4.txt'\n",
    "midi_paths['P1T5'] = '../MIDI/MIDI-P01-task5.txt'\n",
    "midi_paths['P1T6'] = '../MIDI/MIDI-P01-task6.txt'\n",
    "midi_paths['P1T7'] = '../MIDI/MIDI-P01-task7.txt'\n",
    "midi_paths['P1T8'] = '../MIDI/MIDI-P01-task8.txt'\n",
    "midi_paths['P1T9'] = '../MIDI/MIDI-P01-task9.txt'\n",
    "midi_paths['P1T10'] = '../MIDI/MIDI-P01-task10.txt'\n",
    "midi_paths['P1T11'] = '../MIDI/MIDI-P01-task11.txt'\n",
    "midi_paths['P1T12'] = '../MIDI/MIDI-P01-task12.txt'\n",
    "\n",
    "midi_paths['P2T1'] = '../MIDI/MIDI-P02-task1.txt'\n",
    "midi_paths['P2T2'] = '../MIDI/MIDI-P02-task2.txt'\n",
    "midi_paths['P2T3'] = '../MIDI/MIDI-P02-task3.txt'\n",
    "midi_paths['P2T4'] = '../MIDI/MIDI-P02-task4.txt'\n",
    "midi_paths['P2T5'] = '../MIDI/MIDI-P02-task5.txt'\n",
    "midi_paths['P2T6'] = '../MIDI/MIDI-P02-task6.txt'\n",
    "midi_paths['P2T7'] = '../MIDI/MIDI-P02-task7.txt'\n",
    "midi_paths['P2T8'] = '../MIDI/MIDI-P02-task8.txt'\n",
    "midi_paths['P2T9'] = '../MIDI/MIDI-P02-task9.txt'\n",
    "midi_paths['P2T10'] = '../MIDI/MIDI-P02-task10.txt'\n",
    "midi_paths['P2T11'] = '../MIDI/MIDI-P02-task11.txt'\n",
    "midi_paths['P2T12'] = '../MIDI/MIDI-P02-task12.txt'\n",
    "\n",
    "midi_paths['P3T1'] = '../MIDI/MIDI-P03-task1.txt'\n",
    "midi_paths['P3T2'] = '../MIDI/MIDI-P03-task2.txt'\n",
    "midi_paths['P3T3'] = '../MIDI/MIDI-P03-task3.txt'\n",
    "midi_paths['P3T4'] = '../MIDI/MIDI-P03-task4.txt'\n",
    "midi_paths['P3T5'] = '../MIDI/MIDI-P03-task5.txt'\n",
    "midi_paths['P3T6'] = '../MIDI/MIDI-P03-task6.txt'\n",
    "midi_paths['P3T7'] = '../MIDI/MIDI-P03-task7.txt'\n",
    "midi_paths['P3T8'] = '../MIDI/MIDI-P03-task8.txt'\n",
    "midi_paths['P3T9'] = '../MIDI/MIDI-P03-task9.txt'\n",
    "midi_paths['P3T10'] = '../MIDI/MIDI-P03-task10.txt'\n",
    "midi_paths['P3T11'] = '../MIDI/MIDI-P03-task11.txt'\n",
    "midi_paths['P3T12'] = '../MIDI/MIDI-P03-task12.txt'\n",
    "\n",
    "midi_paths['P4T1'] = '../MIDI/MIDI-P04-task1.txt'\n",
    "midi_paths['P4T2'] = '../MIDI/MIDI-P04-task2.txt'\n",
    "midi_paths['P4T3'] = '../MIDI/MIDI-P04-task3.txt'\n",
    "midi_paths['P4T4'] = '../MIDI/MIDI-P04-task4.txt'\n",
    "midi_paths['P4T5'] = '../MIDI/MIDI-P04-task5.txt'\n",
    "midi_paths['P4T6'] = '../MIDI/MIDI-P04-task6.txt'\n",
    "midi_paths['P4T7'] = '../MIDI/MIDI-P04-task7.txt'\n",
    "midi_paths['P4T8'] = '../MIDI/MIDI-P04-task8.txt'\n",
    "midi_paths['P4T9'] = '../MIDI/MIDI-P04-task9.txt'\n",
    "midi_paths['P4T10'] = '../MIDI/MIDI-P04-task10.txt'\n",
    "midi_paths['P4T11'] = '../MIDI/MIDI-P04-task11.txt'\n",
    "midi_paths['P4T12'] = '../MIDI/MIDI-P04-task12.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7d0065",
   "metadata": {},
   "source": [
    "### DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ca68b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "P1T1 = pd.read_csv(midi_paths['P1T1'], sep=' ')\n",
    "P1T2 = pd.read_csv(midi_paths['P1T2'], sep=' ')\n",
    "P1T3 = pd.read_csv(midi_paths['P1T3'], sep=' ')\n",
    "P1T4 = pd.read_csv(midi_paths['P1T4'], sep=' ')\n",
    "P1T5 = pd.read_csv(midi_paths['P1T5'], sep=' ')\n",
    "P1T6 = pd.read_csv(midi_paths['P1T6'], sep=' ')\n",
    "P1T7 = pd.read_csv(midi_paths['P1T7'], sep=' ')\n",
    "P1T8 = pd.read_csv(midi_paths['P1T8'], sep=' ')\n",
    "P1T9 = pd.read_csv(midi_paths['P1T9'], sep=' ')\n",
    "P1T10 = pd.read_csv(midi_paths['P1T10'], sep=' ')\n",
    "P1T11 = pd.read_csv(midi_paths['P1T11'], sep=' ')\n",
    "P1T12 = pd.read_csv(midi_paths['P1T12'], sep=' ')\n",
    "P1 = [P1T1, P1T2, P1T3, P1T4, P1T5, P1T6, P1T7, P1T8, P1T9, P1T10, P1T11, P1T12]\n",
    "\n",
    "P2T1 = pd.read_csv(midi_paths['P2T1'], sep=' ')\n",
    "P2T2 = pd.read_csv(midi_paths['P2T2'], sep=' ')\n",
    "P2T3 = pd.read_csv(midi_paths['P2T3'], sep=' ')\n",
    "P2T4 = pd.read_csv(midi_paths['P2T4'], sep=' ')\n",
    "P2T5 = pd.read_csv(midi_paths['P2T5'], sep=' ')\n",
    "P2T6 = pd.read_csv(midi_paths['P2T6'], sep=' ')\n",
    "P2T7 = pd.read_csv(midi_paths['P2T7'], sep=' ')\n",
    "P2T8 = pd.read_csv(midi_paths['P2T8'], sep=' ')\n",
    "P2T9 = pd.read_csv(midi_paths['P2T9'], sep=' ')\n",
    "P2T10 = pd.read_csv(midi_paths['P2T10'], sep=' ')\n",
    "P2T11 = pd.read_csv(midi_paths['P2T11'], sep=' ')\n",
    "P2T12 = pd.read_csv(midi_paths['P2T12'], sep=' ')\n",
    "P2 = [P2T1, P2T2, P2T3, P2T4, P2T5, P2T6, P2T7, P2T8, P2T9, P2T10, P2T11, P2T12]\n",
    "\n",
    "P3T1 = pd.read_csv(midi_paths['P3T1'], sep=' ')\n",
    "P3T2 = pd.read_csv(midi_paths['P3T2'], sep=' ')\n",
    "P3T3 = pd.read_csv(midi_paths['P3T3'], sep=' ')\n",
    "P3T4 = pd.read_csv(midi_paths['P3T4'], sep=' ')\n",
    "P3T5 = pd.read_csv(midi_paths['P3T5'], sep=' ')\n",
    "P3T6 = pd.read_csv(midi_paths['P3T6'], sep=' ')\n",
    "P3T7 = pd.read_csv(midi_paths['P3T7'], sep=' ')\n",
    "P3T8 = pd.read_csv(midi_paths['P3T8'], sep=' ')\n",
    "P3T9 = pd.read_csv(midi_paths['P3T9'], sep=' ')\n",
    "P3T10 = pd.read_csv(midi_paths['P3T10'], sep=' ')\n",
    "P3T11 = pd.read_csv(midi_paths['P3T11'], sep=' ')\n",
    "P3T12 = pd.read_csv(midi_paths['P3T12'], sep=' ')\n",
    "P3 = [P3T1, P3T2, P3T3, P3T4, P3T5, P3T6, P3T7, P3T8, P3T9, P3T10, P3T11, P3T12]\n",
    "\n",
    "P4T1 = pd.read_csv(midi_paths['P4T1'], sep=' ')\n",
    "P4T2 = pd.read_csv(midi_paths['P4T2'], sep=' ')\n",
    "P4T3 = pd.read_csv(midi_paths['P4T3'], sep=' ')\n",
    "P4T4 = pd.read_csv(midi_paths['P4T4'], sep=' ')\n",
    "P4T5 = pd.read_csv(midi_paths['P4T5'], sep=' ')\n",
    "P4T6 = pd.read_csv(midi_paths['P4T6'], sep=' ')\n",
    "P4T7 = pd.read_csv(midi_paths['P4T7'], sep=' ')\n",
    "P4T8 = pd.read_csv(midi_paths['P4T8'], sep=' ')\n",
    "P4T9 = pd.read_csv(midi_paths['P4T9'], sep=' ')\n",
    "P4T10 = pd.read_csv(midi_paths['P4T10'], sep=' ')\n",
    "P4T11 = pd.read_csv(midi_paths['P4T11'], sep=' ')\n",
    "P4T12 = pd.read_csv(midi_paths['P4T12'], sep=' ')\n",
    "P4 = [P4T1, P4T2, P4T3, P4T4, P4T5, P4T6, P4T7, P4T8, P4T9, P4T10, P4T11, P4T12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c76820",
   "metadata": {},
   "source": [
    "### Removing excess columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98b3e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_df(participant):\n",
    "    for df in participant:\n",
    "        # Remove unwanted columns\n",
    "        for i in df.columns:\n",
    "            # Use only 'Velocity'\n",
    "            if i != 'Velocity':\n",
    "                df.drop(i, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7749bbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_df(P1)\n",
    "trim_df(P2)\n",
    "trim_df(P3)\n",
    "trim_df(P4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bd6fe5",
   "metadata": {},
   "source": [
    "### Making a dictionary of participants/tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11942dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "\n",
    "for p in range(4):\n",
    "    participant = 'P' + str(p + 1)\n",
    "    dataframes[participant] = {}\n",
    "    \n",
    "for t in range(12):\n",
    "    task = 'task' + str(t + 1)\n",
    "    dataframes['P1'][task] = P1[t]\n",
    "    dataframes['P2'][task] = P2[t]\n",
    "    dataframes['P3'][task] = P3[t]\n",
    "    dataframes['P4'][task] = P4[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e895dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes['P4']['task1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7b47ff",
   "metadata": {},
   "source": [
    "# Average Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b24f5f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframes['P4']['task1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4391a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes['P4']['task1'].std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1611120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a dictionary of Average Pupil Size for task of each participant:\n",
    "avg_vel_dict = {}\n",
    "\n",
    "for prt in dataframes:\n",
    "    # Participant\n",
    "    avg_vel_dict[prt] = {}\n",
    "    for tsk in dataframes[prt]:\n",
    "        # Task\n",
    "        avg_vel_dict[prt][tsk] = {}\n",
    "        avg_vel_dict[prt][tsk][tsk+'_mean'] = dataframes[prt][tsk].mean()[0]\n",
    "        avg_vel_dict[prt][tsk][tsk+'_std'] = dataframes[prt][tsk].std(ddof=0)[0]        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e37ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_vel_dict['P4']['task1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85704b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Printing the mean of the velocities of each task pr participant\n",
    "print('\\nAverage Velocity')\n",
    "for prt in avg_vel_dict:\n",
    "    # Participant\n",
    "    print(f'\\n{prt}\\t{\"\": <3}Mean{\"\": <5}\\tStd\\n')\n",
    "    for tsk in avg_vel_dict[prt]:\n",
    "        # The mean rounded to 5 decimals\n",
    "        print(tsk, f'\\t{\"\": <3}{avg_vel_dict[prt][tsk][tsk+\"_mean\"]:.5}{\"\": <3}\\t{avg_vel_dict[prt][tsk][tsk+\"_std\"]:.5}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36530943",
   "metadata": {},
   "source": [
    "## Plotting the Average Velocity of each task pr participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d55289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a list of labels\n",
    "labels = []\n",
    "\n",
    "# Task labels (similar for all participants)\n",
    "for tsk in avg_vel_dict['P1']:\n",
    "    labels.append(tsk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b1f387",
   "metadata": {},
   "source": [
    "### Making lists for plotting bars and errorbars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49659b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a list of Velocity means & std\n",
    "avg_vel_plot = []\n",
    "avg_vel_yerr = []\n",
    "\n",
    "\n",
    "# Participant\n",
    "for i, prt in enumerate(avg_vel_dict):\n",
    "    avg_vel_plot.append([])\n",
    "    avg_vel_yerr.append([])\n",
    "    # Task\n",
    "    for tsk in avg_vel_dict[prt]:\n",
    "        avg_vel_plot[i].append(avg_vel_dict[prt][tsk][tsk+'_mean'])\n",
    "        avg_vel_yerr[i].append(avg_vel_dict[prt][tsk][tsk+'_std'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330f895b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(24, 12), sharey=True)\n",
    "\n",
    "fig.suptitle('Average Velocity', fontsize=32)\n",
    "\n",
    "rects1 = axs[0,0].bar(labels, avg_vel_plot[0], color='c')\n",
    "rects2 = axs[0,1].bar(labels, avg_vel_plot[1], color='m')\n",
    "rects3 = axs[1,0].bar(labels, avg_vel_plot[2], color='y')\n",
    "rects4 = axs[1,1].bar(labels, avg_vel_plot[3], color='g')\n",
    "\n",
    "axs[0,0].set_title('P1', fontsize=16)\n",
    "axs[0,1].set_title('P2', fontsize=16)\n",
    "axs[1,0].set_title('P3', fontsize=16)\n",
    "axs[1,1].set_title('P4', fontsize=16)\n",
    "\n",
    "axs[0,0].set_ylim(0)\n",
    "axs[0,1].set_ylim(0)\n",
    "axs[1,0].set_ylim(0)\n",
    "axs[1,1].set_ylim(0)\n",
    "\n",
    "axs[0,0].bar_label(rects1)\n",
    "axs[0,1].bar_label(rects2)\n",
    "axs[1,0].bar_label(rects3)\n",
    "axs[1,1].bar_label(rects4)\n",
    "\n",
    "# Border between Impro and Scales\n",
    "axs[0,0].axvline(x=4.5, ls=':', lw=2, c='r')\n",
    "axs[0,1].axvline(x=4.5, ls=':', lw=2, c='r')\n",
    "axs[1,0].axvline(x=4.5, ls=':', lw=2, c='r')\n",
    "axs[1,1].axvline(x=4.5, ls=':', lw=2, c='r')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('./plots/vel_bar.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318e9703",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(24, 12), sharey=True)\n",
    "\n",
    "fig.suptitle('Average Velocity (w/errorbars)', fontsize=32)\n",
    "\n",
    "rects1 = axs[0,0].bar(labels, avg_vel_plot[0], yerr=avg_vel_yerr[0], capsize=6, color='c')\n",
    "rects2 = axs[0,1].bar(labels, avg_vel_plot[1], yerr=avg_vel_yerr[1], capsize=6, color='m')\n",
    "rects3 = axs[1,0].bar(labels, avg_vel_plot[2], yerr=avg_vel_yerr[2], capsize=6, color='y')\n",
    "rects4 = axs[1,1].bar(labels, avg_vel_plot[3], yerr=avg_vel_yerr[3], capsize=6, color='g')\n",
    "\n",
    "axs[0,0].set_title('P1', fontsize=16)\n",
    "axs[0,1].set_title('P2', fontsize=16)\n",
    "axs[1,0].set_title('P3', fontsize=16)\n",
    "axs[1,1].set_title('P4', fontsize=16)\n",
    "\n",
    "axs[0,0].set_ylim(0)\n",
    "axs[0,1].set_ylim(0)\n",
    "axs[1,0].set_ylim(0)\n",
    "axs[1,1].set_ylim(0)\n",
    "\n",
    "axs[0,0].bar_label(rects1, label_type='center')\n",
    "axs[0,1].bar_label(rects2, label_type='center')\n",
    "axs[1,0].bar_label(rects3, label_type='center')\n",
    "axs[1,1].bar_label(rects4, label_type='center')\n",
    "\n",
    "# Border between Impro and Scales\n",
    "axs[0,0].axvline(x=4.5, ls=':', lw=2, c='r')\n",
    "axs[0,1].axvline(x=4.5, ls=':', lw=2, c='r')\n",
    "axs[1,0].axvline(x=4.5, ls=':', lw=2, c='r')\n",
    "axs[1,1].axvline(x=4.5, ls=':', lw=2, c='r')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('./plots/vel_errorbar.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2627d0d0",
   "metadata": {},
   "source": [
    "## Comparing Participants pr task for each case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0e1a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.4  # the width of the bars\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(24,6))\n",
    "rects1 = axs.bar(x - width/2, avg_vel_plot[0], width/2, label='P1')\n",
    "rects2 = axs.bar(x, avg_vel_plot[1], width/2, label='P2')\n",
    "rects3 = axs.bar(x + width/2, avg_vel_plot[2], width/2, label='P3')\n",
    "rects4 = axs.bar(x + width, avg_vel_plot[3], width/2, label='P4')\n",
    "\n",
    "\n",
    "# Add text for labels, title and custom x-axis tick labels, etc.\n",
    "axs.set_ylabel('Velocity (Mean)', fontsize=16)\n",
    "axs.set_title('Average Velocity by Participant Comparison', pad=16, fontsize=24)\n",
    "axs.set_xticks(x+0.1, labels)\n",
    "axs.legend()\n",
    "\n",
    "\n",
    "# Adding bar labels (mean)\n",
    "axs.bar_label(rects1, fmt='%.1f')\n",
    "axs.bar_label(rects2, fmt='%.1f')\n",
    "axs.bar_label(rects3, fmt='%.1f')\n",
    "axs.bar_label(rects4, fmt='%.1f')\n",
    "\n",
    "# Border between Impro and Scales\n",
    "axs.axvline(x=3.6, ls=':', lw=2, c='r')\n",
    "\n",
    "\n",
    "# Tightening, plotting and saving\n",
    "fig.tight_layout()\n",
    "plt.savefig('./plots/vel_participant_comparison_bar.pdf')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75e394d",
   "metadata": {},
   "source": [
    "# Mean across participants (pr task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f4145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a new dataframe for Z-score means\n",
    "task_avg = pd.DataFrame(index=np.arange(1,13))\n",
    "task_avg.index.name = 'Task'\n",
    "\n",
    "# Using the Z-score values\n",
    "for i, prt in enumerate(avg_vel_plot):\n",
    "    task_avg[f'P{i+1}'] = avg_vel_plot[i]\n",
    "    \n",
    "# Adding column with Means\n",
    "task_avg['task_mean'] = task_avg.mean(axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4aeac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b65e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "\n",
    "fig.suptitle('Average MIDI Velocity (0-127)', fontsize=26)\n",
    "\n",
    "ax.bar(labels, task_avg['task_mean'], label='Velocity (Mean)')\n",
    "\n",
    "ax.set_ylabel('Velocity', fontsize=12)\n",
    "\n",
    "# Border between Impro and Scales\n",
    "ax.axvline(x=3.5, ls=':', lw=2, c='r', alpha=0.5)\n",
    "\n",
    "ax.set_ylim(0,128)\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./plots/vel_avg.pdf\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70e588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "\n",
    "fig.suptitle('Average MIDI Velocity (Zoomed)', fontsize=26)\n",
    "\n",
    "ax.bar(labels, task_avg['task_mean'], label='Velocity (Mean)')\n",
    "\n",
    "ax.set_ylabel('Velocity', fontsize=12)\n",
    "\n",
    "# Border between Impro and Scales\n",
    "ax.axvline(x=3.5, ls=':', lw=2, c='r', alpha=0.5)\n",
    "\n",
    "ax.set_ylim(60,74)\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./plots/vel_avg_zoom.pdf\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb7d1ce",
   "metadata": {},
   "source": [
    "## Exporting Pupil plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c45f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "folder = './plot_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601c905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(avg_vel_plot, folder+'avg_vel_plot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
